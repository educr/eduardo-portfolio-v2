---
slug: planq
title: "PlanQ"
summary: "Growing a radiation oncology tool to a new user group"
category:
  - Healthcare
featured: true
role:
  - Visual Design
  - Interaction Design
  - Research
  - Information Architecture
team:
  - Cross-departmental (Patient Education, Brand, UX Design)
year: 2025
cover: "/cases/planq/cover.jpg"
---

![Hero](/cases/planq/hero.png)

## Roles & Team

**My Roles:** Research, Interaction Design, Information Architecture, Visual Design  
**Team:** Cross-departmental collaboration with UX design, medical physics, and clinical staff.  

---

## Challenges

- The existing tool served some radiation therapy related roles but needed to expand to **radiation therapists**.  
- **No designers** had ever worked on the project, leading to heavy design debt.  
- The dashboard’s **large table had too many columns**, requiring constant side-scrolling.  
- Needed to **introduce and differentiate AI features** in a high-risk clinical context.  
<figure>
  <img src="/cases/planq/audit.png" />
  <figcaption>View of original tool being audited by team</figcaption>
</figure>
---

## Process

The project demanded close collaboration with both **clinical staff** and **engineers**.  
- I partnered with clinical staff to gather **data requirements**, mapping what information was critical at different steps of their workflow.  
- In parallel, I worked with **developers** to understand technical constraints, such as how PlanQ’s APIs could or could not interact with existing clinical systems. This dialogue helped balance **ambition with feasibility**, ensuring the designs respected integration limits while still aiming for meaningful improvements.  

We began with a **visual design audit**, reconciling inconsistent patterns across the interface. From there, I assisted with creating a foundation for **consistent design standards** that would scale as the product evolved.  

We then conducted **on-site research** at MSK's Main Campus and a regional site, observing how radiation therapists worked in real clinical environments. These studies revealed workflow bottlenecks, circuitous flows, role-specific needs, and moments where visual hierarchy failed.  
<figure>
  <img src="/cases/planq/observation.png" />
  <figcaption>On-site observation</figcaption>
</figure>
To validate early concepts, we built **interactive Figma prototypes** and ran **user testing sessions with real therapists**. These sessions provided direct insights into usability and trust, guiding refinements before handoff.  

---

## Solutions

- **Dashboard views tailored** to different radiation therapy tasks.  
- **Visual design reconciliation** to reduce clutter and unify the interface.  
- Introduced a **card view** alongside the table view — supporting scannable workflows for therapists while retaining dense data for physicists. 
<img src="/cases/planq/card-view.png" />
- Developed a **distinct style** for AI-generated or AI-flagged content, balancing clarity with clinical safety.  
<img src="/cases/planq/ai.png" />




---


## Impact

Although I left MSK before the designs went into production, **user testing yielded encouraging results**:  

- Some therapists reported that they **preferred the card view**.  
- While there was **healthy skepticism toward AI features**, some therapists acknowledged potential value if used with thorough caution.  
- Filtering **helped therapists quickly locate the data they needed**.  
- One therapist remarked the design **exceeded expectations**, and some expressed excitement at seeing a workflow tool shaped directly around their needs.  

Meanwhile, developers appreciated that the proposed solutions were **grounded in API and integration realities**, which eased adoption discussions.  

- The team adopted **more consistent visuals**, making for a more unified product.  
- In principle, once the new dashboard was deployed there would be smoother transitions between different tasks.  

---

## Reflection

This project highlighted the importance of **direct observation in clinical settings**. Many of the most impactful design improvements came not from interviews but from **watching therapists work under real conditions**.  

It also reinforced the value of **early engagement with both clinicians and engineers**. By bridging the gap between **workflow requirements** and **technical feasibility**, we ensured the design was not only desirable but also possible.  

Most importantly, the **user testing feedback confirmed impact even before release**. Seeing therapists’ excitement — and their cautious optimism toward AI — underscored the importance of involving end-users in the design process.  
